import aiohttp
import asyncio
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from dateutil.parser import parse
from config import KEYWORDS, EXCLUDED_KEYWORDS
import sys

BASE_URL = "https://gorvesti.ru"
FEED_URL = "https://gorvesti.ru/feed/"

async def fetch_gorvesti_news():
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–∞—Ä—Å–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ —Å https://gorvesti.ru/feed/ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—É—Ç–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º, —Å—Å—ã–ª–∫–æ–π –∏ –¥–∞—Ç–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.
    """
    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π GET-–∑–∞–ø—Ä–æ—Å
        async with aiohttp.ClientSession() as session:
            async with session.get(FEED_URL, timeout=10, ssl=False) as response:
                response.raise_for_status()
                content = await response.text()

        # –ü–∞—Ä—Å–∏–º HTML-–∫–æ–¥
        soup = BeautifulSoup(content, "html.parser")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π
        news_blocks = soup.find_all("div", class_="itm")
        if not news_blocks:
            print(f"‚ùóÔ∏è –î–ª—è —Å–∞–π—Ç–∞ {BASE_URL} –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.")
            return []

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ—Ä–æ–≥ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—É—Ç–∫–∏)
        cutoff_time = datetime.now() - timedelta(days=1)

        # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π
        news_items = []

        for item in news_blocks:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title_tag = item.find("h2")
            title = title_tag.get_text(strip=True) if title_tag else None

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω
            if not title:
                continue

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫—É
            link = BASE_URL + title_tag.find_parent("a")["href"] if title_tag and title_tag.find_parent("a") else None
            if not link:
                continue

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É
            date_tag = item.find("span", class_="dt")
            date_str = date_tag.get_text(strip=True) if date_tag else None

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—É –≤ –æ–±—ä–µ–∫—Ç datetime
            try:
                date = parse(date_str, dayfirst=True)
            except Exception:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ
            if date < cutoff_time:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ä—ã–µ –Ω–æ–≤–æ—Å—Ç–∏

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            if any(kw.lower() in title.lower() for kw in KEYWORDS):
                if not any(ex_kw.lower() in title.lower() for ex_kw in EXCLUDED_KEYWORDS):
                    news_items.append({
                        "title": title,
                        "link": link,
                        "date": date.strftime("%d.%m.%y %H:%M")  # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –≤ —Ç—Ä–µ–±—É–µ–º–æ–º –≤–∏–¥–µ
                    })

        return news_items

    except aiohttp.ClientError as e:
        print(f"‚ùóÔ∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ —Å–∞–π—Ç—É {BASE_URL}: {e}")
        return []
    except Exception as e:
        print(f"‚ùóÔ∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
        return []


def display_news(news_items):
    """
    –í—ã–≤–æ–¥–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ —Ç—Ä–µ–±—É–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
    –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º –∏ —Å—Å—ã–ª–∫–∞–º.
    """
    if not news_items:
        print(f"‚ùóÔ∏è –î–ª—è —Å–∞–π—Ç–∞ {BASE_URL} –Ω–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º!")
        print(f"{'-' * 50}")
        return

    seen_links = set()  # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
    seen_titles = set()  # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤

    for item in news_items:
        if item['link'] not in seen_links and item['title'] not in seen_titles:
            seen_links.add(item['link'])
            seen_titles.add(item['title'])
            print(
                f"üì¢ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {item['title']}\n"
                f"üîó –°—Å—ã–ª–∫–∞: {item['link']}\n"
                f"üìÖ –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {item['date']}\n"
                f"{'-' * 50}"
            )


async def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π.
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    if not KEYWORDS:
        print("‚ùóÔ∏è –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ —É–∫–∞–∑–∞–Ω—ã.")
        sys.exit(1)

    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏
    news = await fetch_gorvesti_news()

    # –í—ã–≤–æ–¥–∏–º –Ω–æ–≤–æ—Å—Ç–∏
    display_news(news)


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É
    asyncio.run(main())