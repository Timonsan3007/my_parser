import aiohttp
import asyncio
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from email.utils import parsedate_tz, mktime_tz
import feedparser  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º feedparser
from config import KEYWORDS, EXCLUDED_KEYWORDS

async def fetch_riac34_news():
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–∞—Ä—Å–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ —Å riac34.ru –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π."""
    rss_url = 'https://riac34.ru/rss/'
    news_list = []

    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(rss_url, ssl=False) as response:
                response.raise_for_status()
                feed_content = await response.text()

                # –ü–∞—Ä—Å–∏–º RSS-–ª–µ–Ω—Ç—É —Å –ø–æ–º–æ—â—å—é feedparser
                feed = feedparser.parse(feed_content)

                if len(feed.entries) == 0:
                    print("‚ùóÔ∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏.")
                    return []

                now = datetime.now()

                for entry in feed.entries:
                    title = entry.title
                    link = entry.link
                    description = entry.description if hasattr(entry, 'description') else ""
                    pub_date = entry.published if hasattr(entry, 'published') else None

                    if not pub_date:
                        print(f"‚ùóÔ∏è –û—à–∏–±–∫–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏ '{title}'.")
                        continue

                    pub_date = pub_date.replace(",", "")
                    parsed_date = parsedate_tz(pub_date)

                    if parsed_date:
                        pub_date_obj = datetime.fromtimestamp(mktime_tz(parsed_date))
                        if now - pub_date_obj > timedelta(days=1):
                            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ —Å—Ç–∞—Ä—à–µ 24 —á–∞—Å–æ–≤

                        formatted_date = pub_date_obj.strftime("%d.%m.%y %H:%M")

                        if (
                            any(keyword.lower() in title.lower() or keyword.lower() in description.lower() for keyword in KEYWORDS)
                            and not any(excluded.lower() in title.lower() or excluded.lower() in description.lower() for excluded in EXCLUDED_KEYWORDS)
                        ):
                            news_list.append({
                                "title": title,
                                "link": link,
                                "date": formatted_date
                            })
                    else:
                        print(f"‚ùóÔ∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç—ã: {pub_date}")

    except Exception as e:
        print(f"‚ùóÔ∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–æ–≤–æ—Å—Ç–∏ –≤ —Å–ø–∏—Å–∫–µ
    if not news_list:
        print(f"‚ùóÔ∏è –î–ª—è —Å–∞–π—Ç–∞ {rss_url} –Ω–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º!")
        print(f"{'-' * 50}")

    return news_list

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π."""
    news = await fetch_riac34_news()

    # –í—ã–≤–æ–¥–∏–º –Ω–æ–≤–æ—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    for item in news:
        print(f"üì¢ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {item['title']}\n"
              f"üîó –°—Å—ã–ª–∫–∞: {item['link']}\n"
              f"üìÖ –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {item['date']}\n"
              f"{'-' * 50}")

if __name__ == "__main__":
    asyncio.run(main())